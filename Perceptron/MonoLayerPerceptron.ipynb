{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRYEofSD0xoF"
      },
      "source": [
        "# Perceptron monocapa\n",
        "\n",
        "Un perceptrón monocapa está compuesto de una capa pasiva de entrada, y una sola capa activa que también sirve de capa de salida.\n",
        "\n",
        "El input de un perceptron determina el estado de las neuronas pasivas de la capa de entrada, $x$.\n",
        "Se considera, además, una neurona pasiva de estado fijo $x_{n_e}=-1$, para que haga las veces de umbral de activación.\n",
        "Ante una entrada $x$, la salida de la red neuronal viene dada por\n",
        "$$\n",
        "y_j(x)\n",
        "=\n",
        "g(h_{j}(x))\n",
        "$$\n",
        "donde\n",
        "$$\n",
        "h_j\n",
        "=\n",
        "%\\sum_{i=1}^{n_e}\n",
        "\\sum_i\n",
        "w_{ji}x_i\n",
        "$$\n",
        "para $j=1,...,n_s$, y $g$ es una función de activación.\n",
        "Por ejemplo, una ReLU, la cual viene dada por\n",
        "$g(h) = h$ si $h>0$ y $g(h)=0$ si $h\\leq 0$.\n",
        "\n",
        "Para entrenar la red, usamos como función costo el error cuadrático sobre el conjunto de entrenamiento $\\{e_m,s_m:m=1,...,M\\}$, al cuál lo expresamos como una función de $w$\n",
        "$$\n",
        "E(w)\n",
        "=\n",
        "\\frac{1}{2}\n",
        "%\\sum_{m=1}^M\n",
        "\\sum_{m}\n",
        "%\\sum_{j=1}^{n_s}\n",
        "\\sum_{j}\n",
        "(y_{jm}(w)-s_{mj})^2\n",
        "$$\n",
        "donde $s_{mj}$ es la salida deseada en la $j$-ésima neurona ante el $m$-ésimo ejemplo, $y_{mj}$ es la salida obtenida en la $j$-esima neurona ante el $m$-ésimo ejemplo, y $n_s$ es el número de neuronas de salida.\n",
        "Por otro lado,\n",
        "$$\n",
        "y_{jm}(w)\n",
        "=\n",
        "g(h_{jm}(w))\n",
        "$$\n",
        "donde\n",
        "$$\n",
        "h_{jm}(w)\n",
        "=\n",
        "\\sum_{i=0}^{n_e}\n",
        "w_{ji}e_{mi}\n",
        "$$\n",
        "Nos interesa calcular el gradiente de $E(w)$\n",
        "\\begin{eqnarray}\n",
        "\\frac{\\partial E}{\\partial w_{pq}}\n",
        "&=&\n",
        "%\\sum_{m=1}^M\n",
        "\\sum_m\n",
        "%\\sum_{j=1}^{n_s}\n",
        "\\sum_j\n",
        "(y_{jm}(w)-s_{mj})\n",
        "\\frac{\\partial y_{jm}}{\\partial w_{pq}}\n",
        "\\\\\n",
        "&=&\n",
        "%\\sum_{m=1}^M\n",
        "\\sum_m\n",
        "%\\sum_{j=1}^{n_s}\n",
        "\\sum_j\n",
        "(y_{jm}(w)-s_{mj})\n",
        "g'(h_{jm}(w))\n",
        "\\frac{\\partial h_{jm}}{\\partial w_{pq}}\n",
        "\\\\\n",
        "&=&\n",
        "%\\sum_{m=1}^M\n",
        "\\sum_m\n",
        "%\\sum_{j=1}^{n_s}\n",
        "\\sum_j\n",
        "(y_{jm}(w)-s_{mj})\n",
        "g'(h_{jm}(w))\n",
        "\\delta_{jp}\n",
        "e_{mq}\n",
        "\\\\\n",
        "&=&\n",
        "%\\sum_{m=1}^M\n",
        "\\sum_m\n",
        "(y_{pm}(w)-s_{mp})\n",
        "g'(h_{pm}(w))\n",
        "e_{mq}\n",
        "\\end{eqnarray}\n",
        "puesto que\n",
        "$$\n",
        "\\frac{\\partial h_{jm}}{\\partial w_{pq}}\n",
        "=\n",
        "%\\sum_{i=1}^{n_e}\n",
        "\\sum_i\n",
        "\\frac{w_{ji}}{w_{pq}}\n",
        "e_{mi}\n",
        "=\n",
        "%\\sum_{i=1}^{n_e}\n",
        "\\sum_i\n",
        "\\delta_{jp}\n",
        "\\delta_{iq}\n",
        "e_{mi}\n",
        "=\n",
        "\\delta_{jp}\n",
        "e_{mq}\n",
        "$$\n",
        "\n",
        "Recordar que, en el caso de una ReLU, $g'(h)=\\Theta(h)$, donde $\\Theta(h)=1$ si $h>0$ y $\\Theta(h)=0$ si $h\\leq 0$.\n",
        "\n",
        "Para actualizar los pesos sinápticos en la $(\\tau+1)$-ésima época de entrenamiento, utilice la regla\n",
        "$$\n",
        "w^{\\tau}_{ji} \\to w^{\\tau+1}_{ji} = w^{\\tau}_{ji} - \\eta \\frac{\\partial E}{\\partial w_{ji}}\n",
        "$$\n",
        "para todo $ji$.\n",
        "\n",
        "## **Ejercicio 1**\n",
        "\n",
        "Genere un conjunto de entrenamiento compuesto por $M$ puntos en $\\mathbb{R}^{n_e}$, distribuidos en $n_s$ nubes, con $m_c$ puntos en la nube $c$.\n",
        "Notar que $c=1,...,n_e$ nubes y, en total, se generarán $M=\\sum_c m_c$ puntos.\n",
        "\n",
        "Para generar las nubes:\n",
        "\n",
        "* genere aleatoriamente $n_s$ puntos en $\\mathbb{R}^{n_e}$ a los que llamaremos centros, sorteando los valores de las coordenadas a partir de una distribución normal, y\n",
        "\n",
        "* para cada centro $c$, genere $m_c$ puntos aleatorios alrededor del mismo, sumando sus coordenadas a números aleatorios generados con una Gaussiana de desviación estandard $\\sigma=0.1$.\n",
        "\n",
        "Las $n_e$ coordenadas del $m$-ésimo punto constituirán el vector de entrada del $m$-ésimo ejemplo.\n",
        "La nube a la que pertenece el $m$-ésimo punto determinará el vector de salida del $m$-ésimo ejemplo.\n",
        "Más precisamente, si el $m$-ésimo punto pertenence a la $c$-ésima nube, el vector de salida será el vector canónico $(0,0,...,1,...,0)$ de $n_s$ componentes con un único 1 en la $c$-esima posición.\n",
        "\n",
        "Concretamente\n",
        "\n",
        "1. Genere un conjunto de 8 puntos en $\\mathbb{R}^{n_e}$ con $n_e=2$, divididos en 3 nubes con $m_1=3$ en la primera nube, $m_2=2$ puntos en la segunda nube y $m_3=3$ puntos en la tercera nube. Utilice $\\sigma=0.1$ para indicar la dispersión de los puntos alrededor de cada nube.\n",
        "\n",
        "2. Grafique las nubes de puntos, utilizando un color distinto para cada una de ellas.\n",
        "\n",
        "**IMPORTANTE:** No olvide extender la entrada con una unidad extra de estado fijo $x_{n_e+1}=-1$ para que las sinapsis $w_{j,n_e+1}$ hagan las veces de umbrales $u_j$.\n",
        "\n",
        "## **Ejercicio 2**\n",
        "\n",
        "Implemente y entrene un **perceptrón monocapa** sobre el conjunto de entrenamiento generado en el Ejercicio 1.\n",
        "Utilice funciones de activación **sigmoideas** y, además, recuerde agregar las neuronas auxiliares que permiten imitar los umbrales de activación.\n",
        "\n",
        "Para entrenarlo, utilice una taza $\\eta=0.02$ y alrededor de 500.000 de épocas o más, según considere necesario.\n",
        "\n",
        "Luego, grafique nuevamente los puntos, pintando el relleno de los mismos con los colores de las nubes asociadas, y el borde de los mismos con el color correspondiente a la predicción.\n",
        "Grafique, además, las predicciones antes de entrar con el fin de corroborar que la red sin entregar clasifica erroneamente los ejemplos.\n",
        "\n",
        "## **Ejercicio 3**\n",
        "\n",
        "La compuerta XOR.\n",
        "\n",
        "El siguiente conjunto de 4 ejemplos:\n",
        "\n",
        "* $e_1 = (0,0,-1)$, $s_1=(1,0)$\n",
        "* $e_2 = (0,1,-1)$, $s_2=(0,1)$\n",
        "* $e_3 = (1,0,-1)$, $s_3=(0,1)$\n",
        "* $e_4 = (1,1,-1)$, $s_4=(1,0)$\n",
        "\n",
        "corresponde a la compuerta XOR.\n",
        "Utilice el **perceptrón monocapa** implementando para verificar que el mismo no es capáz de aprender este conjunto de ejemplos.\n",
        "\n",
        "## **Ejercicio 4**\n",
        "\n",
        "Repita los experimentos utilizando funciones de activación de tipo **ReLU**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "UjbcNI0a4ac3"
      },
      "outputs": [],
      "source": [
        "# 1.1)\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def puntos_aleatorios(n=3):\n",
        "    return [np.array([random.uniform(-10, 10), random.uniform(-10, 10)]) for _ in range(n)]\n",
        "\n",
        "num_puntos = [3,2,3]\n",
        "\n",
        "puntos = puntos_aleatorios()\n",
        "\n",
        "grupos = [[], [], []]\n",
        "\n",
        "for i in range(3):\n",
        "    for _ in range(num_puntos[i]):\n",
        "        grupos[i].append(puntos[i] + np.array(np.random.normal(0, 0.1, 2)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1,1, figsize=(12,6))\n",
        "\n",
        "plt.scatter(*zip(*grupos[0]), color='purple', marker='o')\n",
        "plt.scatter(*zip(*grupos[1]), color='green', marker='o')\n",
        "plt.scatter(*zip(*grupos[2]), color='orange', marker='o')\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "def single_layer_perceptron(entry_layer ,n_entry, n_output, Ws, act_fct = lambda x: x):\n",
        "\n",
        "    Ws_copy = Ws.copy()\n",
        "    entry_layer_copy = np.array(entry_layer).copy()\n",
        "\n",
        "    entry_layer_copy = np.append(entry_layer_copy, -1)\n",
        "\n",
        "    output = np.zeros(n_output)\n",
        "    for j in range(n_output):\n",
        "        for i in range(n_entry + 1):\n",
        "            output[j] += Ws_copy[i * n_output + j] * entry_layer_copy[i]\n",
        "        output[j] = act_fct(output[j])\n",
        "\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[81. 81.]\n"
          ]
        }
      ],
      "source": [
        "W = [1, 1, 1, 1, 1, 1 ,1, 1]\n",
        "entry = [5, 2, 3]\n",
        "\n",
        "print(single_layer_perceptron(entry_layer=entry,\n",
        "                              n_entry=3,\n",
        "                              n_output=2,\n",
        "                              Ws=W,\n",
        "                              act_fct=lambda x: x**2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
