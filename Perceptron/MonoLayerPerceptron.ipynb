{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRYEofSD0xoF"
   },
   "source": [
    "# Perceptron monocapa\n",
    "\n",
    "Un perceptrón monocapa está compuesto de una capa pasiva de entrada, y una sola capa activa que también sirve de capa de salida.\n",
    "\n",
    "El input de un perceptron determina el estado de las neuronas pasivas de la capa de entrada, $x$.\n",
    "Se considera, además, una neurona pasiva de estado fijo $x_{n_e}=-1$, para que haga las veces de umbral de activación.\n",
    "Ante una entrada $x$, la salida de la red neuronal viene dada por\n",
    "$$\n",
    "y_j(x)\n",
    "=\n",
    "g(h_{j}(x))\n",
    "$$\n",
    "donde\n",
    "$$\n",
    "h_j\n",
    "=\n",
    "%\\sum_{i=1}^{n_e}\n",
    "\\sum_i\n",
    "w_{ji}x_i\n",
    "$$\n",
    "para $j=1,...,n_s$, y $g$ es una función de activación.\n",
    "Por ejemplo, una ReLU, la cual viene dada por\n",
    "$g(h) = h$ si $h>0$ y $g(h)=0$ si $h\\leq 0$.\n",
    "\n",
    "Para entrenar la red, usamos como función costo el error cuadrático sobre el conjunto de entrenamiento $\\{e_m,s_m:m=1,...,M\\}$, al cuál lo expresamos como una función de $w$\n",
    "$$\n",
    "E(w)\n",
    "=\n",
    "\\frac{1}{2}\n",
    "%\\sum_{m=1}^M\n",
    "\\sum_{m}\n",
    "%\\sum_{j=1}^{n_s}\n",
    "\\sum_{j}\n",
    "(y_{jm}(w)-s_{mj})^2\n",
    "$$\n",
    "donde $s_{mj}$ es la salida deseada en la $j$-ésima neurona ante el $m$-ésimo ejemplo, $y_{mj}$ es la salida obtenida en la $j$-esima neurona ante el $m$-ésimo ejemplo, y $n_s$ es el número de neuronas de salida.\n",
    "Por otro lado,\n",
    "$$\n",
    "y_{jm}(w)\n",
    "=\n",
    "g(h_{jm}(w))\n",
    "$$\n",
    "donde\n",
    "$$\n",
    "h_{jm}(w)\n",
    "=\n",
    "\\sum_{i=0}^{n_e}\n",
    "w_{ji}e_{mi}\n",
    "$$\n",
    "Nos interesa calcular el gradiente de $E(w)$\n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial E}{\\partial w_{pq}}\n",
    "&=&\n",
    "%\\sum_{m=1}^M\n",
    "\\sum_m\n",
    "%\\sum_{j=1}^{n_s}\n",
    "\\sum_j\n",
    "(y_{jm}(w)-s_{mj})\n",
    "\\frac{\\partial y_{jm}}{\\partial w_{pq}}\n",
    "\\\\\n",
    "&=&\n",
    "%\\sum_{m=1}^M\n",
    "\\sum_m\n",
    "%\\sum_{j=1}^{n_s}\n",
    "\\sum_j\n",
    "(y_{jm}(w)-s_{mj})\n",
    "g'(h_{jm}(w))\n",
    "\\frac{\\partial h_{jm}}{\\partial w_{pq}}\n",
    "\\\\\n",
    "&=&\n",
    "%\\sum_{m=1}^M\n",
    "\\sum_m\n",
    "%\\sum_{j=1}^{n_s}\n",
    "\\sum_j\n",
    "(y_{jm}(w)-s_{mj})\n",
    "g'(h_{jm}(w))\n",
    "\\delta_{jp}\n",
    "e_{mq}\n",
    "\\\\\n",
    "&=&\n",
    "%\\sum_{m=1}^M\n",
    "\\sum_m\n",
    "(y_{pm}(w)-s_{mp})\n",
    "g'(h_{pm}(w))\n",
    "e_{mq}\n",
    "\\end{eqnarray}\n",
    "puesto que\n",
    "$$\n",
    "\\frac{\\partial h_{jm}}{\\partial w_{pq}}\n",
    "=\n",
    "%\\sum_{i=1}^{n_e}\n",
    "\\sum_i\n",
    "\\frac{w_{ji}}{w_{pq}}\n",
    "e_{mi}\n",
    "=\n",
    "%\\sum_{i=1}^{n_e}\n",
    "\\sum_i\n",
    "\\delta_{jp}\n",
    "\\delta_{iq}\n",
    "e_{mi}\n",
    "=\n",
    "\\delta_{jp}\n",
    "e_{mq}\n",
    "$$\n",
    "\n",
    "Recordar que, en el caso de una ReLU, $g'(h)=\\Theta(h)$, donde $\\Theta(h)=1$ si $h>0$ y $\\Theta(h)=0$ si $h\\leq 0$.\n",
    "\n",
    "Para actualizar los pesos sinápticos en la $(\\tau+1)$-ésima época de entrenamiento, utilice la regla\n",
    "$$\n",
    "w^{\\tau}_{ji} \\to w^{\\tau+1}_{ji} = w^{\\tau}_{ji} - \\eta \\frac{\\partial E}{\\partial w_{ji}}\n",
    "$$\n",
    "para todo $ji$.\n",
    "\n",
    "## **Ejercicio 1**\n",
    "\n",
    "Genere un conjunto de entrenamiento compuesto por $M$ puntos en $\\mathbb{R}^{n_e}$, distribuidos en $n_s$ nubes, con $m_c$ puntos en la nube $c$.\n",
    "Notar que $c=1,...,n_e$ nubes y, en total, se generarán $M=\\sum_c m_c$ puntos.\n",
    "\n",
    "Para generar las nubes:\n",
    "\n",
    "* genere aleatoriamente $n_s$ puntos en $\\mathbb{R}^{n_e}$ a los que llamaremos centros, sorteando los valores de las coordenadas a partir de una distribución normal, y\n",
    "\n",
    "* para cada centro $c$, genere $m_c$ puntos aleatorios alrededor del mismo, sumando sus coordenadas a números aleatorios generados con una Gaussiana de desviación estandard $\\sigma=0.1$.\n",
    "\n",
    "Las $n_e$ coordenadas del $m$-ésimo punto constituirán el vector de entrada del $m$-ésimo ejemplo.\n",
    "La nube a la que pertenece el $m$-ésimo punto determinará el vector de salida del $m$-ésimo ejemplo.\n",
    "Más precisamente, si el $m$-ésimo punto pertenence a la $c$-ésima nube, el vector de salida será el vector canónico $(0,0,...,1,...,0)$ de $n_s$ componentes con un único 1 en la $c$-esima posición.\n",
    "\n",
    "Concretamente\n",
    "\n",
    "1. Genere un conjunto de 8 puntos en $\\mathbb{R}^{n_e}$ con $n_e=2$, divididos en 3 nubes con $m_1=3$ en la primera nube, $m_2=2$ puntos en la segunda nube y $m_3=3$ puntos en la tercera nube. Utilice $\\sigma=0.1$ para indicar la dispersión de los puntos alrededor de cada nube.\n",
    "\n",
    "2. Grafique las nubes de puntos, utilizando un color distinto para cada una de ellas.\n",
    "\n",
    "**IMPORTANTE:** No olvide extender la entrada con una unidad extra de estado fijo $x_{n_e+1}=-1$ para que las sinapsis $w_{j,n_e+1}$ hagan las veces de umbrales $u_j$.\n",
    "\n",
    "## **Ejercicio 2**\n",
    "\n",
    "Implemente y entrene un **perceptrón monocapa** sobre el conjunto de entrenamiento generado en el Ejercicio 1.\n",
    "Utilice funciones de activación **sigmoideas** y, además, recuerde agregar las neuronas auxiliares que permiten imitar los umbrales de activación.\n",
    "\n",
    "Para entrenarlo, utilice una taza $\\eta=0.02$ y alrededor de 500.000 de épocas o más, según considere necesario.\n",
    "\n",
    "Luego, grafique nuevamente los puntos, pintando el relleno de los mismos con los colores de las nubes asociadas, y el borde de los mismos con el color correspondiente a la predicción.\n",
    "Grafique, además, las predicciones antes de entrar con el fin de corroborar que la red sin entregar clasifica erroneamente los ejemplos.\n",
    "\n",
    "## **Ejercicio 3**\n",
    "\n",
    "La compuerta XOR.\n",
    "\n",
    "El siguiente conjunto de 4 ejemplos:\n",
    "\n",
    "* $e_1 = (0,0,-1)$, $s_1=(1,0)$\n",
    "* $e_2 = (0,1,-1)$, $s_2=(0,1)$\n",
    "* $e_3 = (1,0,-1)$, $s_3=(0,1)$\n",
    "* $e_4 = (1,1,-1)$, $s_4=(1,0)$\n",
    "\n",
    "corresponde a la compuerta XOR.\n",
    "Utilice el **perceptrón monocapa** implementando para verificar que el mismo no es capáz de aprender este conjunto de ejemplos.\n",
    "\n",
    "## **Ejercicio 4**\n",
    "\n",
    "Repita los experimentos utilizando funciones de activación de tipo **ReLU**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "id": "UjbcNI0a4ac3"
   },
   "outputs": [],
   "source": [
    "# 1.1)\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def puntos_aleatorios(n=3):\n",
    "    return [np.array([random.uniform(-10, 10), random.uniform(-10, 10)]) for _ in range(n)]\n",
    "\n",
    "num_puntos = [3,2,3]\n",
    "\n",
    "puntos = puntos_aleatorios()\n",
    "\n",
    "grupos = [[], [], []]\n",
    "\n",
    "for i in range(3):\n",
    "    for _ in range(num_puntos[i]):\n",
    "        grupos[i].append(puntos[i] + np.array(np.random.normal(0, 0.1, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9QAAAH5CAYAAABgeXZFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAiZUlEQVR4nO3df5DddX3v8dfusiyJ7nIJ+UHibkigMxJ+aCDBjFCcWEmItFYmBVqhHaBObL2JTRpGDb1VyBTBSMRgowiOtZ1pc4GLUFsqTHZAILR4oYn0ShuC3DZNDBBIr2Yj6yzH3b1/xKzG/Nr9wNlzsvt4OIyc7373fN+ZfU9mnnz3nNPQ39/fHwAAAGBIGms9AAAAAByNBDUAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUOCYWg9wOH19fXnxxRfT2tqahoaGWo8DAADACNff3589e/ZkypQpaWw8/D3oug7qF198MR0dHbUeAwAAgFFm+/btaW9vP+w5dR3Ura2tSfb+Qdra2mo8DUerSqWS9evXZ/78+Wlubq71OJDEXlKf7CX1yF5Sj+zlyNbV1ZWOjo6BHj2cug7qfb/m3dbWJqgpVqlUMnbs2LS1tfkLj7phL6lH9pJ6ZC+pR/ZydBjMy469KRkAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAUENQAAABQQ1AAAAFBAUAMAAEABQQ0AAAAFBDUAAAAUOKbWAwAAAHBwvX292bBtQ17a81Imt07OBVMvSFNjU63H4mcENQAAQB26b/N9WfrQ0vyg6wcDx9rb2nPbgtuycMbCJIK71gQ1AABAnblv83259J5L05/+/Y7v6NqRS++5NPdefm+SHDG4qS5BDQAAUEd6+3qz9KGlB8R0kvSnPw1pyEf+/iP5r5/81wFf/8XgFtXV503JAAAA6siGbRv2u+v8y/rTf9CY3ve1JFn20LL09vVWZT5+TlADAADUkZf2vPSGvr8//dnetT0btm14kybiUAQ1AABAHZncOvlNeZ43GuYcmaAGAACoIxdMvSDtbe1pSMMbep43K8w5NEENAABQR5oam3LbgtuS5ICobvjZ/04cc+Ihg7shDelo68gFUy+o+qyjnaAGAACoMwtnLMy9l9+bt7W9bb/j7W3tuffye3PnB+5McvDgTpI1C9b4POphMGxB/dnPfjYNDQ1ZtmzZcF0SAADgqLVwxsJsXbo1377q21m3cF2+fdW38x9L/yMLZyw8YnD7yKzhMSyfQ/3000/njjvuyDve8Y7huBwAAMCI0NTYlLnT5h70awtnLMwH3/7BbNi2IS/teSmTWyfngqkXuDM9jKoe1D/+8Y9z5ZVX5qtf/WpuvPHGw57b09OTnp6egcddXV1JkkqlkkqlUtU5Gbn27Y4dop7YS+qRvaQe2UvqUb3t5flvO3/g3/t6+9LX21fDaY5+Q/m5NvT39/dXcZZcddVVGTduXL7whS9k7ty5mTlzZtasWXPQc2+44YasXLnygOPr1q3L2LFjqzkmAAAApLu7O1dccUV2796dtra2w55b1TvUd911VzZt2pSnn356UOdfd911Wb58+cDjrq6udHR0ZP78+Uf8g8ChVCqVdHZ2Zt68eWlubq71OJDEXlKf7CX1yF5Sj+zlyLbvN6UHo2pBvX379ixdujSdnZ057rjjBvU9LS0taWlpOeB4c3OzReUNs0fUI3tJPbKX1CN7ST2ylyPTUH6mVQvqjRs35pVXXsk555wzcKy3tzePP/541q5dm56enjQ1ebE8AAAAR6eqBfX73ve+fO9739vv2DXXXJPTTjstn/zkJ8U0AAAAR7WqBXVra2vOPPPM/Y695S1vyYknnnjAcQAAADjaNNZ6AAAAADgaVf1zqH/Ro48+OpyXAwAAgKpxhxoAAAAKCGoAAAAoIKgBAACggKAGAACAAoIaAAAACghqAAAAKCCoAQAAoICgBgAAgAKCGgAAAAoIagAAACggqAEAAKCAoAYAAIACghoAAAAKCGoAAAAoIKgBAACggKAGAACAAoIaAAAACghqAAAAKCCoAQAAoICgBgAAgAKCGgAAAAoIagAAACggqAEAAKCAoAYAAIACghoAAAAKCGoAAAAoIKgBAACggKAGAACAAoIaAAAACghqAAAAKCCoAQAAoICgBgAAgALH1HoAAAAAjj59vX3ZtmFb9ry0J62TWzP1gqlpbDr4PduhnHs0EdQAAAAMyeb7NuehpQ+l6wddA8fGThibi798cc649IwjntvW3pYFty3IjIUzhm3majj6/5MAAAAAw2bzfZtzz6X37BfISdL9anfuvezedH6i84jndu3oyj2X3pPN920elpmrRVADAAAwKH29fXlo6UNJ/6HP+adb/in/+r/+9fDn/uzYQ8seSl9vX1VmHQ6CGgAAgEHZtmHbAXebD+Zbi7+VrY9uPfy5/UnX9q5s27DtTZxweAlqAAAABmXPS3sGdV73q93Z+ujWN/U565GgBgAAYFBaJ7ceFc85XAQ1AAAAgzL1gqkZO2HsoM6dNnda2trbkoZDnNCQtHW0ZeoFU9+8AYeZoAYAAGBQGpsac/GXLz7ieW0dbZk2d1oW3LZg74FfjuqfPV6wZsFR/XnUR+/kAAAADLszLj0j5338vEOf0PDzUJ6xcEYuv/fytL2tbb9T2trbcvm9lx/1n0N9TK0HAAAA4Ogy73PzMuXcKfnWf/9Wund1Dxxv62jLgjUL9gvlGQtn5O0ffHu2bdiWPS/tSevk1ky9YOpRfWd6H0ENAADAkJ1x2RmZsXDGoEK5sakx0+ZOG/4hq0xQAwAAUGSkhvJgHf332AEAAKAGBDUAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAUENQAAABQQ1AAAAFBAUAMAAEABQQ0AAAAFBDUAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAUENQAAABQQ1AAAAFBAUAMAAEABQQ0AAAAFqhrUN998c84999y0trZm4sSJueSSS7Jly5ZqXhIAAACGRVWD+rHHHsvixYvzne98J52dnalUKpk/f35ee+21al4WAAAAqu6Yaj75Qw89tN/jv/zLv8zEiROzcePGvOc976nmpQEAAKCqqhrUv2z37t1JknHjxh306z09Penp6Rl43NXVlSSpVCqpVCrVH5ARad/u2CHqib2kHtlL6pG9pB7Zy5FtKD/Xhv7+/v4qzjKgr68vv/mbv5kf/ehHeeKJJw56zg033JCVK1cecHzdunUZO3ZstUcEAABglOvu7s4VV1yR3bt3p62t7bDnDltQf/SjH82DDz6YJ554Iu3t7Qc952B3qDs6OrJr164j/kHgUCqVSjo7OzNv3rw0NzfXehxIYi+pT/aSemQvqUf2cmTr6urK+PHjBxXUw/Ir30uWLMkDDzyQxx9//JAxnSQtLS1paWk54Hhzc7NF5Q2zR9Qje0k9spfUI3tJPbKXI9NQfqZVDer+/v587GMfy/33359HH30006dPr+blAAAAYNhUNagXL16cdevW5Zvf/GZaW1vz8ssvJ0mOP/74jBkzppqXBgAAgKqq6udQ33777dm9e3fmzp2byZMnD/xz9913V/OyAAAAUHVV/5VvAAAAGImqeocaAAAARipBDQAAAAUENQAAABQQ1AAAAFBAUAMAAEABQQ0AAAAFBDUAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAUENQAAABQQ1AAAAFBAUAMAAEABQQ0AAAAFBDUAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAUENQAAABQQ1AAAAFBAUAMAAEABQQ0AAAAFBDUAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAUENQAAABQQ1AAAAFBAUAMAAEABQQ0AAAAFBDUAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAUENQAAABQQ1AAAAFBAUAMAAEABQQ0AAAAFBDUAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAUENQAAABQQ1AAAAFBAUAMAAEABQQ0AAAAFBDUAAAAUENQAAABQQFADAABAAUENAAAABYYlqL/0pS9l2rRpOe644zJnzpw89dRTw3FZAAAAqJqqB/Xdd9+d5cuX5/rrr8+mTZvyzne+MxdddFFeeeWVal8aAAAAqqbqQX3rrbdm0aJFueaaa3L66afnK1/5SsaOHZu/+Iu/qPalAQAAoGqOqeaTv/7669m4cWOuu+66gWONjY258MIL8+STTx5wfk9PT3p6egYed3V1JUkqlUoqlUo1R2UE27c7doh6Yi+pR/aSemQvqUf2cmQbys+1qkG9a9eu9Pb2ZtKkSfsdnzRpUp577rkDzr/55puzcuXKA46vX78+Y8eOrdqcjA6dnZ21HgEOYC+pR/aSemQvqUf2cmTq7u4e9LlVDeqhuu6667J8+fKBx11dXeno6Mj8+fPT1tZWw8k4mlUqlXR2dmbevHlpbm6u9TiQxF5Sn+wl9cheUo/s5ci27zelB6OqQT1+/Pg0NTVl586d+x3fuXNnTjrppAPOb2lpSUtLywHHm5ubLSpvmD2iHtlL6pG9pB7ZS+qRvRyZhvIzreqbkh177LGZNWtWHn744YFjfX19efjhh/Pud7+7mpcGAACAqqr6r3wvX748V111VWbPnp13vetdWbNmTV577bVcc8011b40AAAAVE3Vg/q3f/u38+qrr+bTn/50Xn755cycOTMPPfTQAW9UBgAAAEeTYXlTsiVLlmTJkiXDcSkAAAAYFlV9DTUAAACMVIIaAAAACghqAAAAKCCoAQAAoICgBgAAgAKCGgAAAAoIagAAACggqAEAAKCAoAYAAIACghoAAAAKCGoAAAAoIKgBAACggKAGAACAAoIaAAAACghqAAAAKCCoAQAAoICgBgAAgAKCGgAAAAoIagAAACggqAEAAKCAoAYAAIACghoAAAAKCGoAAAAoIKgBAACggKAGAACAAoIaAAAACghqAAAAKCCoAQAAoICgBgAAgAKCGgAAAAoIagAAACggqAEAAKCAoAYAAIACghoAAAAKCGoAAAAoIKgBAACggKAGAACAAoIaAAAACghqAAAAKCCoAQAAoICgBgAAgAKCGgAAAAoIagAAACggqAEAAKCAoAYAAIACghoAAAAKCGoAAAAoIKgBAACggKAGAACAAoIaAAAACghqAAAAKCCoAQAAoICgBgAAgAKCGgAAAAoIagAAACggqAEAAKCAoAYAAIACghoAAAAKCGoAAAAoIKgBAACggKAGAACAAoIaAAAACghqAAAAKCCoAQAAoICgBgAAgAKCGgAAAAoIagAAACggqAEAAKCAoAYAAIACghoAAAAKCGoAAAAoULWg3rp1az784Q9n+vTpGTNmTE499dRcf/31ef3116t1SQAAABg2x1TriZ977rn09fXljjvuyK/8yq/k2WefzaJFi/Laa69l9erV1bosAAAADIuqBfWCBQuyYMGCgcennHJKtmzZkttvv/2QQd3T05Oenp6Bx11dXUmSSqWSSqVSrVEZ4fbtjh2inthL6pG9pB7ZS+qRvRzZhvJzrVpQH8zu3bszbty4Q3795ptvzsqVKw84vn79+owdO7aaozEKdHZ21noEOIC9pB7ZS+qRvaQe2cuRqbu7e9DnNvT39/dXcZYBL7zwQmbNmpXVq1dn0aJFBz3nYHeoOzo6smvXrrS1tQ3HmIxAlUolnZ2dmTdvXpqbm2s9DiSxl9Qne0k9spfUI3s5snV1dWX8+PHZvXv3ETt0yHeoV6xYkVWrVh32nM2bN+e0004beLxjx44sWLAgl1122SFjOklaWlrS0tJywPHm5maLyhtmj6hH9pJ6ZC+pR/aSemQvR6ah/EyHHNTXXnttrr766sOec8oppwz8+4svvpj3vve9Oe+883LnnXcO9XIAAABQl4Yc1BMmTMiECRMGde6OHTvy3ve+N7NmzcrXv/71NDb62GsAAABGhqq9KdmOHTsyd+7cnHzyyVm9enVeffXVga+ddNJJ1bosAAAADIuqBXVnZ2deeOGFvPDCC2lvb9/va8P0PmgAAABQNVX7Heyrr746/f39B/0HAAAAjnZe1AwAAAAFBDUAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAUENQAAABQQ1AAAAFBAUAMAAEABQQ0AAAAFBDUAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAUENQAAABQQ1AAAAFBAUAMAAEABQQ0AAAAFBDUAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAUENQAAABQQ1AAAAFBAUAMAAEABQQ0AAAAFBDUAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAUENQAAABQQ1AAAAFBAUAMAAEABQQ0AAAAFBDUAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAUENQAAABQQ1AAAAFBAUAMAAEABQQ0AAAAFBDUAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAUENQAAABQYlqDu6enJzJkz09DQkGeeeWY4LgkAAABVNSxB/YlPfCJTpkwZjksBAADAsKh6UD/44INZv359Vq9eXe1LAQAAwLA5pppPvnPnzixatCh/+7d/m7Fjxx7x/J6envT09Aw87urqSpJUKpVUKpWqzcnItm937BD1xF5Sj+wl9cheUo/s5cg2lJ9rQ39/f381hujv78/FF1+c888/P3/6p3+arVu3Zvr06fnud7+bmTNnHvR7brjhhqxcufKA4+vWrRtUkAMAAMAb0d3dnSuuuCK7d+9OW1vbYc8dclCvWLEiq1atOuw5mzdvzvr163PPPffkscceS1NT06CC+mB3qDs6OrJr164j/kHgUCqVSjo7OzNv3rw0NzfXehxIYi+pT/aSemQvqUf2cmTr6urK+PHjBxXUQ/6V72uvvTZXX331Yc855ZRT8sgjj+TJJ59MS0vLfl+bPXt2rrzyyvzVX/3VAd/X0tJywPlJ0tzcbFF5w+wR9cheUo/sJfXIXlKP7OXINJSf6ZCDesKECZkwYcIRz/viF7+YG2+8ceDxiy++mIsuuih333135syZM9TLAgAAQF2p2puSTZ06db/Hb33rW5Mkp556atrb26t1WQAAABgWw/I51AAAADDSVPVjs37RtGnTUqU3FAcAAIBh5w41AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAUENQAAABQQ1AAAAFBAUAMAAEABQQ0AAAAFBDUAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAUENQAAABQQ1AAAAFBAUAMAAEABQQ0AAAAFBDUAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAUENQAAABQQ1AAAAFBAUAMAAEABQQ0AAAAFBDUAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAUENQAAABQQ1AAAAFBAUAMAAEABQQ0AAAAFBDUAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAUENQAAABQQ1AAAAFBAUAMAAEABQQ0AAAAFBDUAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAUENQAAABQQ1AAAAFBAUAMAAEABQQ0AAAAFBDUAAAAUENQAAABQoKpB/Q//8A+ZM2dOxowZkxNOOCGXXHJJNS9XG329yc5Hk63/c+//9/XWeiIAAACGwTHVeuJvfOMbWbRoUW666ab82q/9Wn7605/m2WefrdblamP7fcnGpUn3D35+bGx7Muu2pGNh7eYCAACg6qoS1D/96U+zdOnS3HLLLfnwhz88cPz000+vxuVqY/t9yYZLk/Tvf7x7x97jF9z75kR1X2/y6obkJy8lYyYnEy5IGpve+PMCAADwhlQlqDdt2pQdO3aksbExZ599dl5++eXMnDkzt9xyS84888xDfl9PT096enoGHnd1dSVJKpVKKpVKNUYt09ebbPxkkuMOcUJDsnFFMvHiNxa/O/4+eeaTeyN9n7FvS2auSt72gfLnHWX27U5d7RCjnr2kHtlL6pG9pB7Zy5FtKD/Xhv7+/v4jnzY0d911Vz70oQ9l6tSpufXWWzNt2rR8/vOfz/r16/P8889n3LhxB/2+G264IStXrjzg+Lp16zJ27Ng3e0wAAADYT3d3d6644ors3r07bW1thz13SEG9YsWKrFq16rDnbN68OZs2bcqVV16ZO+64Ix/5yEeS7L373N7enhtvvDF/8Ad/cNDvPdgd6o6OjuzateuIf5Bhte3e5H9/+MjnzflaMvXSg3/tcHefJ1+cPHjW/l/bT8Pec9//f/z69yBUKpV0dnZm3rx5aW5urvU4kMReUp/sJfXIXlKP7OXI1tXVlfHjxw8qqIf0K9/XXnttrr766sOec8opp+Sll15Ksv9rpltaWnLKKadk27Zth/zelpaWtLS0HHC8ubm5vhb1rZOT/GRw5x1s7u33Jf90sNdf/9+9x8+6Iel+4fDP3f395EffSSbNHdzM1N8eQewl9cleUo/sJfXIXo5MQ/mZDimoJ0yYkAkTJhzxvFmzZqWlpSVbtmzJr/7qrybZ+19xtm7dmpNPPnkol6xPEy7Y+27e3TtyQBQn2XsHuX3veb+sr3fvO4Mf9Pv6937vltsGN8dPXhr0yAAAALy5qvI51G1tbfnDP/zDXH/99Vm/fn22bNmSj370o0mSyy67rBqXHF6NTXs/GitJ0vBLX/zZ41lrDv7r2K9u2P9jtg7Qn7z+/wY3x5jJgzsPAACAN13VPof6lltuyTHHHJPf+73fy09+8pPMmTMnjzzySE444YRqXXJ4dSzc+9FYB/0c6jWH/siswd5VPnZc8voPM+Q74AAAAAyLqgV1c3NzVq9endWrV1frErXXsTB52weH9jnRg72r/PalyfduyN473r8Y1Ue4Aw4AAMCwqFpQjxqNTUN7Y7DBvv76jP+R/Lczh34HHAAAgGEhqIfbvtdfb7g0R7z7XHIHHAAAgGEhqGthKK+/HuodcAAAAIaFoK4Vd58BAACOaoK6ltx9BgAAOGpV5XOoAQAAYKQT1AAAAFBAUAMAAEABQQ0AAAAFBDUAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAUENQAAABQ4ptYDHE5/f3+SpKurq8aTcDSrVCrp7u5OV1dXmpubaz0OJLGX1Cd7ST2yl9Qjezmy7evPfT16OHUd1Hv27EmSdHR01HgSAAAARpM9e/bk+OOPP+w5Df2Dye4a6evry4svvpjW1tY0NDTUehyOUl1dXeno6Mj27dvT1tZW63Egib2kPtlL6pG9pB7Zy5Gtv78/e/bsyZQpU9LYePhXSdf1HerGxsa0t7fXegxGiLa2Nn/hUXfsJfXIXlKP7CX1yF6OXEe6M72PNyUDAACAAoIaAAAACghqRryWlpZcf/31aWlpqfUoMMBeUo/sJfXIXlKP7CX71PWbkgEAAEC9cocaAAAACghqAAAAKCCoAQAAoICgBgAAgAKCGgAAAAoIaka8L33pS5k2bVqOO+64zJkzJ0899VStR2IUu/nmm3PuueemtbU1EydOzCWXXJItW7bUeizYz2c/+9k0NDRk2bJltR6FUW7Hjh353d/93Zx44okZM2ZMzjrrrPzzP/9zrcdiFOvt7c2nPvWpTJ8+PWPGjMmpp56aP/uzP4sPThq9BDUj2t13353ly5fn+uuvz6ZNm/LOd74zF110UV555ZVaj8Yo9dhjj2Xx4sX5zne+k87OzlQqlcyfPz+vvfZarUeDJMnTTz+dO+64I+94xztqPQqj3A9/+MOcf/75aW5uzoMPPph/+7d/y+c///mccMIJtR6NUWzVqlW5/fbbs3bt2mzevDmrVq3K5z73ufz5n/95rUejRnwONSPanDlzcu6552bt2rVJkr6+vnR0dORjH/tYVqxYUePpIHn11VczceLEPPbYY3nPe95T63EY5X784x/nnHPOyZe//OXceOONmTlzZtasWVPrsRilVqxYkX/8x3/Mhg0baj0KDPiN3/iNTJo0KV/72tcGjv3Wb/1WxowZk7/+67+u4WTUijvUjFivv/56Nm7cmAsvvHDgWGNjYy688MI8+eSTNZwMfm737t1JknHjxtV4EkgWL16cX//1X9/v702olb/7u7/L7Nmzc9lll2XixIk5++yz89WvfrXWYzHKnXfeeXn44Yfz/PPPJ0n+5V/+JU888UTe//7313gyauWYWg8A1bJr16709vZm0qRJ+x2fNGlSnnvuuRpNBT/X19eXZcuW5fzzz8+ZZ55Z63EY5e66665s2rQpTz/9dK1HgSTJv//7v+f222/P8uXL8yd/8id5+umn80d/9Ec59thjc9VVV9V6PEapFStWpKurK6eddlqamprS29ubz3zmM7nyyitrPRo1IqgBamTx4sV59tln88QTT9R6FEa57du3Z+nSpens7Mxxxx1X63Egyd7/6Dh79uzcdNNNSZKzzz47zz77bL7yla8Iamrmnnvuyd/8zd9k3bp1OeOMM/LMM89k2bJlmTJlir0cpQQ1I9b48ePT1NSUnTt37nd8586dOemkk2o0Fey1ZMmSPPDAA3n88cfT3t5e63EY5TZu3JhXXnkl55xzzsCx3t7ePP7441m7dm16enrS1NRUwwkZjSZPnpzTTz99v2MzZszIN77xjRpNBMnHP/7xrFixIr/zO7+TJDnrrLPyn//5n7n55psF9SjlNdSMWMcee2xmzZqVhx9+eOBYX19fHn744bz73e+u4WSMZv39/VmyZEnuv//+PPLII5k+fXqtR4K8733vy/e+970888wzA//Mnj07V155ZZ555hkxTU2cf/75B3ys4PPPP5+TTz65RhNB0t3dncbG/ROqqakpfX19NZqIWnOHmhFt+fLlueqqqzJ79uy8613vypo1a/Laa6/lmmuuqfVojFKLFy/OunXr8s1vfjOtra15+eWXkyTHH398xowZU+PpGK1aW1sPeB3/W97ylpx44ole30/N/PEf/3HOO++83HTTTbn88svz1FNP5c4778ydd95Z69EYxT7wgQ/kM5/5TKZOnZozzjgj3/3ud3Prrbfm93//92s9GjXiY7MY8dauXZtbbrklL7/8cmbOnJkvfvGLmTNnTq3HYpRqaGg46PGvf/3rufrqq4d3GDiMuXPn+tgsau6BBx7Iddddl+9///uZPn16li9fnkWLFtV6LEaxPXv25FOf+lTuv//+vPLKK5kyZUo+9KEP5dOf/nSOPfbYWo9HDQhqAAAAKOA11AAAAFBAUAMAAEABQQ0AAAAFBDUAAAAUENQAAABQQFADAABAAUENAAAABQQ1AAAAFBDUAAAAUEBQAwAAQAFBDQAAAAX+P2bmqKYqse1bAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,6))\n",
    "\n",
    "plt.scatter(*zip(*grupos[0]), color='purple', marker='o')\n",
    "plt.scatter(*zip(*grupos[1]), color='green', marker='o')\n",
    "plt.scatter(*zip(*grupos[2]), color='orange', marker='o')\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_layer_perceptron(entry_layer ,n_entry, n_output, Ws, act_fct = lambda x: x):\n",
    "\n",
    "    Ws_copy = Ws.copy()\n",
    "    entry_layer_copy = np.array(entry_layer).copy()\n",
    "\n",
    "    entry_layer_copy = np.append(entry_layer_copy, -1)\n",
    "\n",
    "    output = np.zeros(n_output)\n",
    "    for j in range(n_output):\n",
    "        for i in range(n_entry + 1):\n",
    "            output[j] += Ws_copy[i * n_output + j] * entry_layer_copy[i]\n",
    "        output[j] = act_fct(output[j])\n",
    "\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -3.14352999  -0.89225774 -13.22435515]\n"
     ]
    }
   ],
   "source": [
    "W = [np.random.rand() for _ in range(9)]\n",
    "entry = [0, 0]\n",
    "\n",
    "print(single_layer_perceptron(entry_layer=entry,\n",
    "                              n_entry=2,\n",
    "                              n_output=3,\n",
    "                              Ws=W,\n",
    "                              act_fct=lambda x: 1/(1-math.exp(-x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x: 1/(1-math.exp(-x))\n",
    "\n",
    "def grad(Ws, \n",
    "         n_entry, \n",
    "         n_output, \n",
    "         data, \n",
    "         labels, \n",
    "         predictions, \n",
    "         learning_rate, \n",
    "         d_act_fct=lambda x: sigmoid(x)*(1-sigmoid(x))):\n",
    "\n",
    "    W = np.array(Ws).copy()\n",
    "    data_copy = np.vstack((data, -1 * np.ones((1, data.shape[1])))).copy()\n",
    "\n",
    "    for p in range(n_output):\n",
    "        for q in range(n_entry):\n",
    "            p_d = 0 #Partial derivative\n",
    "            for m in range(data.shape[1]):\n",
    "                h_pm = 0\n",
    "                for i in range(n_entry + 1):\n",
    "                    h_pm += W[i * n_output + p] * data_copy[i, m]\n",
    "                p_d += (labels[p, m] - predictions[m, p]) * d_act_fct(h_pm) * data_copy[m, q]\n",
    "            print(p+q)\n",
    "            W[p+q] -= learning_rate * p_d\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.93533941  8.81176385  8.80182171  8.42440543  8.3320316  -1.07437889\n",
      "  -1.24769788 -0.96848279]\n",
      " [ 2.91251913  2.86641823  2.90429451  4.17223983  4.19679801 -6.12473749\n",
      "  -6.02285255 -6.05899243]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([coord for group in grupos for coord in group]).T\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([np.zeros(8),\n",
    "                   np.ones(8),\n",
    "                   np.zeros(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.empty((3, 0))\n",
    "\n",
    "for i in range(data.shape[1]):\n",
    "\n",
    "    predictions = np.hstack((predictions, single_layer_perceptron(entry_layer=data[:,i],\n",
    "                                                                  n_entry=2,\n",
    "                                                                  n_output=3,\n",
    "                                                                  Ws=W,\n",
    "                                                                  act_fct=lambda x: 1/(1-math.exp(-x))).reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[246], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m W \u001b[38;5;241m=\u001b[39m \u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m         \u001b[49m\u001b[43mn_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m         \u001b[49m\u001b[43mn_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m         \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[242], line 22\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(Ws, n_entry, n_output, data, labels, predictions, learning_rate, d_act_fct)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_entry \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     21\u001b[0m         h_pm \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m W[i \u001b[38;5;241m*\u001b[39m n_output \u001b[38;5;241m+\u001b[39m p] \u001b[38;5;241m*\u001b[39m data_copy[i, m]\n\u001b[1;32m---> 22\u001b[0m     p_d \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (labels[p, m] \u001b[38;5;241m-\u001b[39m \u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;241m*\u001b[39m d_act_fct(h_pm) \u001b[38;5;241m*\u001b[39m data_copy[m, q]\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(p\u001b[38;5;241m+\u001b[39mq)\n\u001b[0;32m     24\u001b[0m W[p\u001b[38;5;241m+\u001b[39mq] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m p_d\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "W = grad(Ws=W,\n",
    "         n_entry=2,\n",
    "         n_output=3,\n",
    "         data=data,\n",
    "         labels=labels,\n",
    "         predictions=predictions,\n",
    "         learning_rate=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72094703, 0.65904848, 0.92114203, 0.130612  , 0.29026994,\n",
       "       0.00187628, 0.28287838, 0.59219518, 0.74877551])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
