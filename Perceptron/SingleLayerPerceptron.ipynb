{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRYEofSD0xoF"
   },
   "source": [
    "# Perceptron monocapa\n",
    "\n",
    "Un perceptrón monocapa está compuesto de una capa pasiva de entrada, y una sola capa activa que también sirve de capa de salida.\n",
    "\n",
    "El input de un perceptron determina el estado de las neuronas pasivas de la capa de entrada, $x$.\n",
    "Se considera, además, una neurona pasiva de estado fijo $x_{n_e}=-1$, para que haga las veces de umbral de activación.\n",
    "Ante una entrada $x$, la salida de la red neuronal viene dada por\n",
    "$$\n",
    "y_j(x)\n",
    "=\n",
    "g(h_{j}(x))\n",
    "$$\n",
    "donde\n",
    "$$\n",
    "h_j\n",
    "=\n",
    "%\\sum_{i=1}^{n_e}\n",
    "\\sum_i\n",
    "w_{ji}x_i\n",
    "$$\n",
    "para $j=1,...,n_s$, y $g$ es una función de activación.\n",
    "Por ejemplo, una ReLU, la cual viene dada por\n",
    "$g(h) = h$ si $h>0$ y $g(h)=0$ si $h\\leq 0$.\n",
    "\n",
    "Para entrenar la red, usamos como función costo el error cuadrático sobre el conjunto de entrenamiento $\\{e_m,s_m:m=1,...,M\\}$, al cuál lo expresamos como una función de $w$\n",
    "$$\n",
    "E(w)\n",
    "=\n",
    "\\frac{1}{2}\n",
    "%\\sum_{m=1}^M\n",
    "\\sum_{m}\n",
    "%\\sum_{j=1}^{n_s}\n",
    "\\sum_{j}\n",
    "(y_{jm}(w)-s_{mj})^2\n",
    "$$\n",
    "donde $s_{mj}$ es la salida deseada en la $j$-ésima neurona ante el $m$-ésimo ejemplo, $y_{mj}$ es la salida obtenida en la $j$-esima neurona ante el $m$-ésimo ejemplo, y $n_s$ es el número de neuronas de salida.\n",
    "Por otro lado,\n",
    "$$\n",
    "y_{jm}(w)\n",
    "=\n",
    "g(h_{jm}(w))\n",
    "$$\n",
    "donde\n",
    "$$\n",
    "h_{jm}(w)\n",
    "=\n",
    "\\sum_{i=0}^{n_e}\n",
    "w_{ji}e_{mi}\n",
    "$$\n",
    "Nos interesa calcular el gradiente de $E(w)$\n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial E}{\\partial w_{pq}}\n",
    "&=&\n",
    "%\\sum_{m=1}^M\n",
    "\\sum_m\n",
    "%\\sum_{j=1}^{n_s}\n",
    "\\sum_j\n",
    "(y_{jm}(w)-s_{mj})\n",
    "\\frac{\\partial y_{jm}}{\\partial w_{pq}}\n",
    "\\\\\n",
    "&=&\n",
    "%\\sum_{m=1}^M\n",
    "\\sum_m\n",
    "%\\sum_{j=1}^{n_s}\n",
    "\\sum_j\n",
    "(y_{jm}(w)-s_{mj})\n",
    "g'(h_{jm}(w))\n",
    "\\frac{\\partial h_{jm}}{\\partial w_{pq}}\n",
    "\\\\\n",
    "&=&\n",
    "%\\sum_{m=1}^M\n",
    "\\sum_m\n",
    "%\\sum_{j=1}^{n_s}\n",
    "\\sum_j\n",
    "(y_{jm}(w)-s_{mj})\n",
    "g'(h_{jm}(w))\n",
    "\\delta_{jp}\n",
    "e_{mq}\n",
    "\\\\\n",
    "&=&\n",
    "%\\sum_{m=1}^M\n",
    "\\sum_m\n",
    "(y_{pm}(w)-s_{mp})\n",
    "g'(h_{pm}(w))\n",
    "e_{mq}\n",
    "\\end{eqnarray}\n",
    "puesto que\n",
    "$$\n",
    "\\frac{\\partial h_{jm}}{\\partial w_{pq}}\n",
    "=\n",
    "%\\sum_{i=1}^{n_e}\n",
    "\\sum_i\n",
    "\\frac{w_{ji}}{w_{pq}}\n",
    "e_{mi}\n",
    "=\n",
    "%\\sum_{i=1}^{n_e}\n",
    "\\sum_i\n",
    "\\delta_{jp}\n",
    "\\delta_{iq}\n",
    "e_{mi}\n",
    "=\n",
    "\\delta_{jp}\n",
    "e_{mq}\n",
    "$$\n",
    "\n",
    "Recordar que, en el caso de una ReLU, $g'(h)=\\Theta(h)$, donde $\\Theta(h)=1$ si $h>0$ y $\\Theta(h)=0$ si $h\\leq 0$.\n",
    "\n",
    "Para actualizar los pesos sinápticos en la $(\\tau+1)$-ésima época de entrenamiento, utilice la regla\n",
    "$$\n",
    "w^{\\tau}_{ji} \\to w^{\\tau+1}_{ji} = w^{\\tau}_{ji} - \\eta \\frac{\\partial E}{\\partial w_{ji}}\n",
    "$$\n",
    "para todo $ji$.\n",
    "\n",
    "## **Ejercicio 1**\n",
    "\n",
    "Genere un conjunto de entrenamiento compuesto por $M$ puntos en $\\mathbb{R}^{n_e}$, distribuidos en $n_s$ nubes, con $m_c$ puntos en la nube $c$.\n",
    "Notar que $c=1,...,n_e$ nubes y, en total, se generarán $M=\\sum_c m_c$ puntos.\n",
    "\n",
    "Para generar las nubes:\n",
    "\n",
    "* genere aleatoriamente $n_s$ puntos en $\\mathbb{R}^{n_e}$ a los que llamaremos centros, sorteando los valores de las coordenadas a partir de una distribución normal, y\n",
    "\n",
    "* para cada centro $c$, genere $m_c$ puntos aleatorios alrededor del mismo, sumando sus coordenadas a números aleatorios generados con una Gaussiana de desviación estandard $\\sigma=0.1$.\n",
    "\n",
    "Las $n_e$ coordenadas del $m$-ésimo punto constituirán el vector de entrada del $m$-ésimo ejemplo.\n",
    "La nube a la que pertenece el $m$-ésimo punto determinará el vector de salida del $m$-ésimo ejemplo.\n",
    "Más precisamente, si el $m$-ésimo punto pertenence a la $c$-ésima nube, el vector de salida será el vector canónico $(0,0,...,1,...,0)$ de $n_s$ componentes con un único 1 en la $c$-esima posición.\n",
    "\n",
    "Concretamente\n",
    "\n",
    "1. Genere un conjunto de 8 puntos en $\\mathbb{R}^{n_e}$ con $n_e=2$, divididos en 3 nubes con $m_1=3$ en la primera nube, $m_2=2$ puntos en la segunda nube y $m_3=3$ puntos en la tercera nube. Utilice $\\sigma=0.1$ para indicar la dispersión de los puntos alrededor de cada nube.\n",
    "\n",
    "2. Grafique las nubes de puntos, utilizando un color distinto para cada una de ellas.\n",
    "\n",
    "**IMPORTANTE:** No olvide extender la entrada con una unidad extra de estado fijo $x_{n_e+1}=-1$ para que las sinapsis $w_{j,n_e+1}$ hagan las veces de umbrales $u_j$.\n",
    "\n",
    "## **Ejercicio 2**\n",
    "\n",
    "Implemente y entrene un **perceptrón monocapa** sobre el conjunto de entrenamiento generado en el Ejercicio 1.\n",
    "Utilice funciones de activación **sigmoideas** y, además, recuerde agregar las neuronas auxiliares que permiten imitar los umbrales de activación.\n",
    "\n",
    "Para entrenarlo, utilice una taza $\\eta=0.02$ y alrededor de 500.000 de épocas o más, según considere necesario.\n",
    "\n",
    "Luego, grafique nuevamente los puntos, pintando el relleno de los mismos con los colores de las nubes asociadas, y el borde de los mismos con el color correspondiente a la predicción.\n",
    "Grafique, además, las predicciones antes de entrar con el fin de corroborar que la red sin entregar clasifica erroneamente los ejemplos.\n",
    "\n",
    "## **Ejercicio 3**\n",
    "\n",
    "La compuerta XOR.\n",
    "\n",
    "El siguiente conjunto de 4 ejemplos:\n",
    "\n",
    "* $e_1 = (0,0,-1)$, $s_1=(1,0)$\n",
    "* $e_2 = (0,1,-1)$, $s_2=(0,1)$\n",
    "* $e_3 = (1,0,-1)$, $s_3=(0,1)$\n",
    "* $e_4 = (1,1,-1)$, $s_4=(1,0)$\n",
    "\n",
    "corresponde a la compuerta XOR.\n",
    "Utilice el **perceptrón monocapa** implementando para verificar que el mismo no es capáz de aprender este conjunto de ejemplos.\n",
    "\n",
    "## **Ejercicio 4**\n",
    "\n",
    "Repita los experimentos utilizando funciones de activación de tipo **ReLU**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "id": "UjbcNI0a4ac3"
   },
   "outputs": [],
   "source": [
    "# 1.1)\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def puntos_aleatorios(n=3):\n",
    "    return [np.array([random.uniform(-10, 10), random.uniform(-10, 10)]) for _ in range(n)]\n",
    "\n",
    "num_puntos = [3,2,3]\n",
    "\n",
    "puntos = puntos_aleatorios()\n",
    "\n",
    "grupos = [[], [], []]\n",
    "\n",
    "for i in range(3):\n",
    "    for _ in range(num_puntos[i]):\n",
    "        grupos[i].append(puntos[i] + np.array(np.random.normal(0, 0.1, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,6))\n",
    "\n",
    "plt.scatter(*zip(*grupos[0]), color='purple', marker='o')\n",
    "plt.scatter(*zip(*grupos[1]), color='green', marker='o')\n",
    "plt.scatter(*zip(*grupos[2]), color='orange', marker='o')\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.51269244,  2.6085989 ,  2.64687417,  8.42910967,  8.26236544,\n",
       "        -7.56224479, -7.42912727, -7.43770611],\n",
       "       [-6.30582127, -6.17743135, -6.20931141,  0.9874638 ,  0.84870321,\n",
       "         8.0709747 ,  8.04716264,  8.21903678]])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([coord for group in grupos for coord in group]).T\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([[1,1,1,0,0,0,0,0],\n",
    "                   [0,0,0,1,1,0,0,0],\n",
    "                   [0,0,0,0,0,1,1,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaring random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.rand(3,3) #There will be two entries, but I am declaring an extra column for the \"-1\"\n",
    "                        # neuron for the umbral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_layer_perceptron(entry_layer, n_entry, n_output, Ws, act_fct = lambda x: x):\n",
    "\n",
    "    Ws_copy = Ws.copy()\n",
    "    entry_layer_copy = np.array(entry_layer).copy()\n",
    "\n",
    "    entry_layer_copy = np.append(entry_layer_copy, -1)\n",
    "\n",
    "    output = np.zeros(n_output)\n",
    "    for j in range(n_output):\n",
    "        for i in range(n_entry + 1):\n",
    "            output[j] += Ws_copy[j,i] * entry_layer_copy[i]\n",
    "        output[j] = act_fct(output[j])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x: 1/(1+math.exp(-x))\n",
    "\n",
    "def gradient_descent(Ws, \n",
    "                     n_entry, \n",
    "                     n_output, \n",
    "                     data, \n",
    "                     labels, \n",
    "                     predictions, \n",
    "                     learning_rate, \n",
    "                     d_act_fct=lambda x: sigmoid(x)*(1-sigmoid(x))):\n",
    "\n",
    "    W = np.array(Ws).copy()\n",
    "    data_copy = np.vstack((data, -1 * np.ones((1, data.shape[1])))).copy() #Adding the umbral\n",
    "\n",
    "    for p in range(n_output):\n",
    "        for q in range(n_entry+1): # +1 for the umbral\n",
    "            p_d = 0 #Partial derivative\n",
    "            for m in range(data_copy.shape[1]):\n",
    "                h_pm = 0\n",
    "                for i in range(n_entry + 1): # +1 for the umbral\n",
    "                    h_pm += W[p,i] * data_copy[i, m]\n",
    "                p_d += (labels[p, m] - predictions[p, m]) * d_act_fct(h_pm) * data_copy[q, m]\n",
    "            W[p, q] -= learning_rate * p_d\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifing points using the random weigths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.empty((3, 0))\n",
    "\n",
    "for i in range(data.shape[1]):\n",
    "\n",
    "    predictions = np.hstack((predictions, single_layer_perceptron(entry_layer=data[:,i],\n",
    "                                                                  n_entry=2,\n",
    "                                                                  n_output=3,\n",
    "                                                                  Ws=W,\n",
    "                                                                  act_fct=lambda x: 1/(1+math.exp(-x))).reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500000):\n",
    "    W = gradient_descent(Ws=W,\n",
    "                         n_entry=2,\n",
    "                         n_output=3,\n",
    "                         data=data,\n",
    "                         labels=labels,\n",
    "                         predictions=predictions,\n",
    "                         learning_rate=0.02)\n",
    "    \n",
    "    predictions = np.empty((3, 0))\n",
    "\n",
    "    for i in range(data.shape[1]):\n",
    "\n",
    "        predictions = np.hstack((predictions, single_layer_perceptron(entry_layer=data[:,i],\n",
    "                                                                      n_entry=2,\n",
    "                                                                      n_output=3,\n",
    "                                                                      Ws=W,\n",
    "                                                                      act_fct=lambda x: 1/(1+math.exp(-x))).reshape(-1, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.51269244 -6.30582127]\n",
      "[ 2.6085989  -6.17743135]\n",
      "[ 2.64687417 -6.20931141]\n",
      "[8.42910967 0.9874638 ]\n",
      "[8.26236544 0.84870321]\n",
      "[-7.56224479  8.0709747 ]\n",
      "[-7.42912727  8.04716264]\n",
      "[-7.43770611  8.21903678]\n"
     ]
    }
   ],
   "source": [
    "for i in range(data.shape[1]):\n",
    "    print(data[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.28090211e-07, 4.15004014e-05, 9.99999366e-01])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_layer_perceptron(entry_layer=[2.51269244, -6.30582127],\n",
    "                        n_entry=2,\n",
    "                        n_output=3,\n",
    "                        Ws=W,\n",
    "                        act_fct=lambda x: 1/(1+math.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
