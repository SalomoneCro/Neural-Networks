{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRYEofSD0xoF"
   },
   "source": [
    "# PyTorch: Aprendiendo Fashion-MNIST\n",
    "\n",
    "## Refs.\n",
    "\n",
    "* https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n",
    "\n",
    "* https://github.com/zalandoresearch/fashion-mnist\n",
    "\n",
    "* https://github.com/pranay414/Fashion-MNIST-Pytorch/blob/master/fashion_mnist.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "I8N3D_nU1_oT"
   },
   "outputs": [],
   "source": [
    "# 1.1)\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QsfFvPYhkCGl"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlinalg\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mskl\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#import dill\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# 1.2)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.linalg as linalg\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "#import dill\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uot5sVNnkCNa"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 1.3)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# 1.3)\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "#from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVCiYt-1kCUi"
   },
   "outputs": [],
   "source": [
    "# 1.4)\n",
    "import google.colab\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcaGEHAd10sb"
   },
   "source": [
    "## **Ejercicio 2)**\n",
    "\n",
    "Bajando y Jugando con el dataset **Fashion-MNIST**.\n",
    "\n",
    "**1)** Baje y transforme (i.e. normalize los valores al rango [0,1]) los conjuntos de entrenamiento y testeo de FashionMNIST.\n",
    "\n",
    "**2)** Explore algunos ejemplos de estos conjuntos. Que formato poseen?\n",
    "\n",
    "**3)** Visitando la página web de FashionMNIST, cree un diccionario de Python `Dict()` asociando cada categoría a un nombre adecuado de la misma.\n",
    "\n",
    "**4)** Grafique un mosaico de 3x3 imagenes de FashionMNIST, cada una titulada con su respectiva clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUoQ9bnwaZ7O",
    "outputId": "12075a20-655e-4309-8cf0-16bedff27786"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:03<00:00, 8.54MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 134kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.42M/4.42M [00:01<00:00, 2.56MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 14.8MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convertir las imágenes a tensores\n",
    "])                          # Esto ya normaliza los valores entre 0 y 1\n",
    "\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\",       # Directorio donde se almacenará el dataset\n",
    "    train=True,          \n",
    "    download=True,       \n",
    "    transform=transform  # Aplicar transformaciones\n",
    ")\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,         # False para descargar el conjunto de prueba\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_labels = {\n",
    "    0: \"T-shirt/top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\"\n",
    "}\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(8, 8))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    image, label = train_dataset[i]  \n",
    "    image = image.squeeze()  # Eliminar la dimensión extra (El canal de grises)\n",
    "    ax.imshow(image, cmap=\"gray\")  \n",
    "    ax.set_title(fashion_mnist_labels[label])  \n",
    "    ax.axis(\"off\")  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OWYnfxWz8RS"
   },
   "source": [
    "## Ejercicio 3)\n",
    "\n",
    "Creando un `DataLoader` para alimentar el modelo con batchs (lotes) de entrenamiento.\n",
    "\n",
    "**1)** Cree los `DataLoader`s para cada conjunto. Defínalos con un `batch_size` de 100 y con el flag `shuffle` seteado a `True`.\n",
    "\n",
    "**2)** Use uno de los `DataLoader`s creados anteriormente para explorar algunos elementos del conjunto.\n",
    "\n",
    "Notar que, el iterador devuelve el batch en un par `(image,label)`.\n",
    "\n",
    "El objeto `images` es un tensor de dimensiones `(100,1,28,28)`.\n",
    "El 100 es el tamaño del batch.\n",
    "El 1 porque hay un solo canal (en este caso, un canal de escala de grises, pero podría haber varios, p. ej. uno por cada color de {Red, Green Blue} en caso que fuesen imagenes a color).\n",
    "Luego, 28 y 28 porque cada imagen del dataset es de 28 x 28 píxeles.\n",
    "\n",
    "El objeto `labels` es un tensor de dimensiones `(100,)`.\n",
    "La $i$-ésima entrada `labels[i]` de `labels` es un número en $\\{0,1,...,9\\}$ indicando la categoría a la que pertenece la $i$-ésima imagen en el batch, guardada en `images[i]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lK7gqh7lrTi8"
   },
   "outputs": [],
   "source": [
    "train_set, valid_set = random_split(train_dataset, [50000, 10000])  # Dividir en train y validación\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=100, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_set, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "# Verificar que se haya cargado correctamente\n",
    "for images, labels in train_loader:\n",
    "    print(f\"Lote de imágenes: {images.size()}, Lote de etiquetas: {labels.size()}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REToccG127zI"
   },
   "source": [
    "## Ejercicio 4)\n",
    "\n",
    "Defina una red neuronal de 4 capas, una de entrada, dos ocultas de $n_1=128$ y $n_2=64$ neuronas, respectivamente, y una de salida de 10 neuronas.\n",
    "\n",
    "En las capas intermedias utilice neuronas tipo ReLU y agregueles un *dropout* de p=0.2.\n",
    "En la capa de salida no utilice funciones de activación ni dropout.\n",
    "\n",
    "Las capas sucesivas tienen que estar totalmente conectadas entre si."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C17Tib9G_k-q"
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        # Definir las capas de la red\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),  # Capa de entrada a la primera capa oculta\n",
    "            nn.ReLU(),                  # Activación ReLU\n",
    "            nn.Dropout(p=0.2),          # Dropout con probabilidad 0.2\n",
    "            nn.Linear(128, 64),         # Primera capa oculta a la segunda\n",
    "            nn.ReLU(),                  # Activación ReLU\n",
    "            nn.Dropout(p=0.2),          # Dropout con probabilidad 0.2\n",
    "            nn.Linear(64, output_size)  # Segunda capa oculta a la salida\n",
    "            # Sin función de activación ni dropout en la capa de salida\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "input_size = 28 * 28  \n",
    "output_size = 10     \n",
    "\n",
    "model = NeuralNet(input_size, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9uINlg69OTw"
   },
   "source": [
    "## Ejercicio 5)\n",
    "\n",
    "Entrenamos el modelo\n",
    "\n",
    "**1)** Implemente, en una función, un loop de entrenamiento que recorra los batchs (lotes).\n",
    "\n",
    "**2)** Implemente, en una función, un loop de validación que recorra los batchs.\n",
    "\n",
    "**3)** Inicialize dos `DataLoader`s llamados `train_loader` y `valid_loader` a partir del `train_set` (conjunto de entranmiento) y del `valid_set` (conjunto de validación) de Fashion-MNIST, respectivamente, y que usen batchs de 100 ejemplos.\n",
    "\n",
    "**4)** Cree una función de pérdida usando la **Cross Entropy Loss**.\n",
    "\n",
    "**IMPORTANTE:** Notar que la **Cross Entropy Loss** aplica automáticamente una `log_softmax`.\n",
    "\n",
    "**5)** Cree un optimizador que utilice el método de **Stochastic Gradient Descent** con un learning rate igual a $10^{-3}$.\n",
    "\n",
    "**6)** Cree una instancia del modelo.\n",
    "\n",
    "**7)** Especifique en que dispositivo (`device`) va a trabajar: en una **CPU** o en una **GPU**.\n",
    "\n",
    "**8)** Implemente un loop de entrenamiento y validación que trabaje con el `train_loader` y el `valid_loader`, respectivamente, usando un numero arbitrario de épocas.\n",
    "Este loop debe guardar en cuatro listas los valores de los promedios del **Cross Entropy Loss** y las fracciones de clasificaciones correctas o **precisión** (accuracy) sobre el conjunto de **entrenamiento** y el de **validación**, respectivamente.\n",
    "\n",
    "**IMPORTANTE:** No olvide copiar los batchs al dispositivo de trabajo.\n",
    "\n",
    "**9)** Entrene y valide el modelo.\n",
    "\n",
    "**10)** Use las listas del inciso anterior para graficar en función de las épocas la **Cross Entropy Loss** de **entrenamiento** y de **validación**.\n",
    "Realize un gráfico análogo pero con la **precisión**.\n",
    "Discuta y comente, cual es el número óptimo de épocas de entrenamiento?\n",
    "\n",
    "**11)** Repita los experimentos variando hiperparámetros. Por ejemplo:\n",
    "\n",
    "- El learning-rate.\n",
    "- El optimizador (ej. puede usar ADAM).\n",
    "- El valor de dropout.\n",
    "- El número de neuronas en las capas intermedias.\n",
    "- El número de épocas de entrenamiento.\n",
    "- El tamaño de los lotes.\n",
    "\n",
    "Discuta los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hyuXv-0x29Xw"
   },
   "outputs": [],
   "source": [
    "def train_loop(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()  # Poner la red en modo de entrenamiento\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)  \n",
    "        data = data.view(data.size(0), -1)  # Aplanar las imágenes (28x28 -> 784)\n",
    "\n",
    "        optimizer.zero_grad()  # Limpiar gradientes previos\n",
    "        output = model(data)  # Paso hacia adelante\n",
    "        loss = criterion(output, target)  # Calcular la pérdida\n",
    "        loss.backward()  # Paso hacia atrás\n",
    "        optimizer.step()  # Actualizar los parámetros\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # Obtener predicciones\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_loop(model, valid_loader, criterion, device):\n",
    "    model.eval()  # Poner la red en modo de evaluación\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():  # Desactivar el cálculo de gradientes\n",
    "        for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "            data, target = data.to(device), target.to(device)  \n",
    "            data = data.view(data.size(0), -1)  \n",
    "\n",
    "            output = model(data)  # Paso hacia adelante\n",
    "            loss = criterion(output, target)  # Calcular la pérdida\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # Obtener predicciones\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(valid_loader)\n",
    "    accuracy = 100. * correct / len(valid_loader.dataset)\n",
    "\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de pérdida\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"Modelo trabajando en: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "train_losses, train_accuracies = [], []\n",
    "valid_losses, valid_accuracies = [], []\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"\\nÉpoca {epoch}/{num_epochs}\")\n",
    "\n",
    "    # Entrenamiento\n",
    "    train_loss, train_accuracy = train_loop(model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Validación\n",
    "    valid_loss, valid_accuracy = valid_loop(model, valid_loader, criterion, device)\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_accuracies.append(valid_accuracy)\n",
    "\n",
    "    print(f\"Resumen - Época {epoch}:\")\n",
    "    print(f\"  Pérdida de entrenamiento: {train_loss:.4f}\")\n",
    "    print(f\"  Pérdida de validación: {valid_loss:.4f}, Precisión de validación: {valid_accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\nEntrenamiento finalizado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Gráfico de pérdidas (Train vs Validation)\n",
    "ax[0].plot(train_losses, label='Pérdida de Entrenamiento', color='blue', linestyle='-', marker='o')\n",
    "ax[0].plot(valid_losses, label='Pérdida de Validación', color='orange', linestyle='--', marker='s')\n",
    "ax[0].set_title('Pérdidas durante el Entrenamiento', fontsize=14)\n",
    "ax[0].set_xlabel('Épocas', fontsize=12)\n",
    "ax[0].set_ylabel('Pérdida', fontsize=12)\n",
    "ax[0].legend(fontsize=10)\n",
    "ax[0].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Gráfico de precisiones (Train vs Validation)\n",
    "ax[1].plot(train_accuracies, label='Precisión de Entrenamiento', color='green', linestyle='-', marker='o')\n",
    "ax[1].plot(valid_accuracies, label='Precisión de Validación', color='red', linestyle='--', marker='s')\n",
    "\n",
    "ax[1].set_title('Precisión durante el Entrenamiento', fontsize=14)\n",
    "ax[1].set_xlabel('Épocas', fontsize=12)\n",
    "ax[1].set_ylabel('Precisión (%)', fontsize=12)\n",
    "ax[1].legend(fontsize=10)\n",
    "ax[1].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
